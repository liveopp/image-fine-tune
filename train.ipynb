{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Training Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用说明\n",
    "\n",
    "* 编辑  \"config/your-config-file.json\"\n",
    "* 编辑 “全局变量”中的 ```config``` 和  ``` run_dir``` 参数\n",
    "* 运行 notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from datasets.dataset import ImageData\n",
    "from nets import dishnet1_7 as dishnet\n",
    "from utils.utils import write_pb, save_model, mkdir_p\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 修改运行相关的变量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = \"config/dishnet-config.json\"\n",
    "run_dir = 'RUN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 准备训练需要的环境，变量，数据，创建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Train on 1083 classes.\n",
      "WARNING:tensorflow:From /root/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(run_dir):\n",
    "    os.makedirs(run_dir)\n",
    "\n",
    "assert (os.path.exists(run_dir) and os.path.isdir( run_dir))\n",
    "assert (os.path.exists(config) and not os.path.isdir( config))\n",
    "hypes = json.load(open(config, 'r'))\n",
    "hypes_train = hypes['train']\n",
    "project_name = hypes_train['project_name']\n",
    "\n",
    "hypes_train['run_dir'] = os.path.join( run_dir, project_name)\n",
    "hypes_train['log_dir'] = os.path.join( run_dir, project_name, 'logs')\n",
    "hypes_train['ckpt_dir'] = os.path.join( run_dir, project_name, 'checkpoints')\n",
    "mkdir_p(hypes_train['run_dir'])\n",
    "mkdir_p(hypes_train['log_dir'])\n",
    "mkdir_p(hypes_train['ckpt_dir'])\n",
    "\n",
    "# 设置log级别\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "# recover variables from the input dict (config file)\n",
    "run_dir = hypes[\"train\"][\"run_dir\"]\n",
    "log_dir = hypes[\"train\"][\"log_dir\"]\n",
    "ckpt_dir = hypes[\"train\"][\"ckpt_dir\"]\n",
    "pretrain_model = hypes[\"train\"][\"pretrain_model\"]\n",
    "data_train = hypes[\"train\"][\"data_train\"]\n",
    "data_val = hypes[\"train\"][\"data_val\"]\n",
    "learning_rate = hypes[\"train\"][\"learning_rate\"]\n",
    "export_model = hypes[\"train\"][\"export_model\"]\n",
    "is_tfrecord = hypes[\"train\"].get(\"tfrecord_flag\", False)\n",
    "batch_size = hypes[\"train\"].get(\"batch_size\", 32)\n",
    "\n",
    "# 数据增强的参数: 获取默认参数，或者从配置文件中加载\n",
    "augment_params = hypes[\"train\"].get(\"augment\", get_default_augment_params())\n",
    "\n",
    "if is_tfrecord:\n",
    "    _num_classes = hypes['train'].get('num_classes', None)\n",
    "    if _num_classes is None:\n",
    "        raise ValueError(\"Missing num_classes setting in the config file when training data is tfrecord files.\")\n",
    "\n",
    "    img_data = ImageData(data_train, data_val,\n",
    "                         is_tfrecord=is_tfrecord,\n",
    "                         batch_size=batch_size,\n",
    "                         augment_params=augment_params,\n",
    "                         output_like='Inception')\n",
    "\n",
    "else:\n",
    "    # 如果只想在部分类别熵测试，可以在配置文件中指定 use_classes\n",
    "    # 例如 \"use_classes\": [\"000101\", \"000011\"]\n",
    "    # 即只使用上面两种类别的数据训练和验证\n",
    "    # 如果 \"use_classes\"为[]或不存在，默认使用全部类别\n",
    "    small_classes_set = None\n",
    "    _classes_set = hypes['train'].get('use_classes', None)\n",
    "    if _classes_set:\n",
    "        small_classes_set = _classes_set\n",
    "\n",
    "    img_data = ImageData(data_train, data_val,\n",
    "                         small_classes_set=small_classes_set,\n",
    "                         batch_size=batch_size,\n",
    "                         augment_params=augment_params,\n",
    "                         output_like='Inception')\n",
    "    _num_classes = len(img_data.classes)\n",
    "\n",
    "\n",
    "# 网络相关的配置参数\n",
    "net_params = {\n",
    "    'num_classes': _num_classes,\n",
    "    'pretrain_model': pretrain_model,\n",
    "    'checkpoint_path': ckpt_dir,\n",
    "    'exclude': ['logits'],\n",
    "    'adam_beta1': hypes_train['adam_beta1']\n",
    "}\n",
    "\n",
    "tf.logging.info('Train on {} classes.'.format(net_params['num_classes']))\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    train_dataset = img_data.data_input_fn(mode='train')\n",
    "    val_dataset = img_data.data_input_fn(mode='eval')\n",
    "    handle = tf.placeholder(tf.string, shape=[])\n",
    "    iterator = tf.data.Iterator.from_string_handle(\n",
    "        handle, train_dataset.output_types, train_dataset.output_shapes)\n",
    "    train_iterator = train_dataset.make_initializable_iterator()\n",
    "    val_iterator = val_dataset.make_initializable_iterator()\n",
    "    images, labels = iterator.get_next()\n",
    "\n",
    "    net = build_net(images, labels, net_params)\n",
    "    net['handle'] = handle\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "# Indicates whether we are in training or in test mode\n",
    "is_training = net['is_training']\n",
    "\n",
    "# create writer to log the training; later for tensorboard\n",
    "train_writer = tf.summary.FileWriter(os.path.join(log_dir, 'train'), graph)\n",
    "eval_writer = tf.summary.FileWriter(os.path.join(log_dir, 'eval'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step 0 -- train loss: 6.913 acc_top1: 0.000 acc_top5: 0.031\n",
      "INFO:tensorflow:step 0 -- on validation set: acc_top1: 0.000 acc_top5: 0.003\n",
      "INFO:tensorflow:step 20 -- train loss: 6.908 acc_top1: 0.125 acc_top5: 0.188\n",
      "INFO:tensorflow:step 40 -- train loss: 6.844 acc_top1: 0.094 acc_top5: 0.125\n",
      "INFO:tensorflow:step 60 -- train loss: 6.410 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 80 -- train loss: 6.748 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 100 -- train loss: 6.682 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 100 -- on validation set: acc_top1: 0.014 acc_top5: 0.020\n",
      "INFO:tensorflow:step 120 -- train loss: 6.838 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 140 -- train loss: 7.074 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 160 -- train loss: 6.864 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 180 -- train loss: 5.654 acc_top1: 0.281 acc_top5: 0.281\n",
      "INFO:tensorflow:step 200 -- train loss: 5.792 acc_top1: 0.312 acc_top5: 0.312\n",
      "INFO:tensorflow:step 200 -- on validation set: acc_top1: 0.020 acc_top5: 0.026\n",
      "INFO:tensorflow:step 220 -- train loss: 6.548 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 240 -- train loss: 6.441 acc_top1: 0.094 acc_top5: 0.125\n",
      "INFO:tensorflow:step 260 -- train loss: 6.524 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 280 -- train loss: 6.160 acc_top1: 0.312 acc_top5: 0.344\n",
      "INFO:tensorflow:step 300 -- train loss: 6.202 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 300 -- on validation set: acc_top1: 0.009 acc_top5: 0.023\n",
      "INFO:tensorflow:step 320 -- train loss: 6.862 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 340 -- train loss: 6.196 acc_top1: 0.188 acc_top5: 0.188\n",
      "INFO:tensorflow:step 360 -- train loss: 5.642 acc_top1: 0.250 acc_top5: 0.250\n",
      "INFO:tensorflow:step 380 -- train loss: 5.896 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 400 -- train loss: 6.518 acc_top1: 0.094 acc_top5: 0.094\n",
      "INFO:tensorflow:step 400 -- on validation set: acc_top1: 0.020 acc_top5: 0.023\n",
      "INFO:tensorflow:step 420 -- train loss: 5.580 acc_top1: 0.250 acc_top5: 0.250\n",
      "INFO:tensorflow:step 440 -- train loss: 6.157 acc_top1: 0.188 acc_top5: 0.219\n",
      "INFO:tensorflow:step 460 -- train loss: 6.084 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 480 -- train loss: 6.564 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 500 -- train loss: 6.251 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 500 -- on validation set: acc_top1: 0.009 acc_top5: 0.011\n",
      "INFO:tensorflow:step 520 -- train loss: 6.597 acc_top1: 0.062 acc_top5: 0.094\n",
      "INFO:tensorflow:step 540 -- train loss: 6.183 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 560 -- train loss: 6.291 acc_top1: 0.156 acc_top5: 0.156\n",
      "INFO:tensorflow:step 580 -- train loss: 6.224 acc_top1: 0.219 acc_top5: 0.250\n",
      "INFO:tensorflow:step 600 -- train loss: 5.753 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 600 -- on validation set: acc_top1: 0.011 acc_top5: 0.014\n",
      "INFO:tensorflow:step 620 -- train loss: 6.126 acc_top1: 0.125 acc_top5: 0.219\n",
      "INFO:tensorflow:step 640 -- train loss: 6.066 acc_top1: 0.188 acc_top5: 0.219\n",
      "INFO:tensorflow:step 660 -- train loss: 6.405 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 680 -- train loss: 6.208 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 700 -- train loss: 6.487 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 700 -- on validation set: acc_top1: 0.014 acc_top5: 0.034\n",
      "INFO:tensorflow:step 720 -- train loss: 6.283 acc_top1: 0.125 acc_top5: 0.125\n",
      "INFO:tensorflow:step 740 -- train loss: 6.012 acc_top1: 0.219 acc_top5: 0.219\n",
      "INFO:tensorflow:step 760 -- train loss: 5.570 acc_top1: 0.250 acc_top5: 0.250\n",
      "INFO:tensorflow:Training finished, evaluating the model on validation set...\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    net['train_handle'] = sess.run(train_iterator.string_handle())\n",
    "    net['val_handle'] = sess.run(val_iterator.string_handle())\n",
    "    # 如果有之前的checkpoint, 从其restore\n",
    "    saved_ckpt = tf.train.latest_checkpoint(ckpt_dir)\n",
    "    if saved_ckpt:\n",
    "        saver.restore(sess, saved_ckpt)\n",
    "\n",
    "    # Here we initialize the iterator with the training set.\n",
    "    # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "    train_and_evaluate(sess, train_iterator, val_iterator,\n",
    "                       train_writer, eval_writer, net,\n",
    "                       saver, hypes, float(learning_rate))\n",
    "    tf.logging.info('Training finished, evaluating the model on validation set...')\n",
    "    eval_result = fully_evaluate(sess, val_iterator, net['eval_metric'],\n",
    "                                 {is_training: False, handle: net['val_handle']}, -1)\n",
    "    tf.logging.info('======= eval result ========')\n",
    "    tf.logging.info(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练完成后导出模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_pb_file(net_params, run_dir, export_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
